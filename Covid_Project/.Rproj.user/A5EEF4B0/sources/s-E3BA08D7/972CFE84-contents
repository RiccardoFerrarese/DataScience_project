---
title: "Modelling"
author: "Massimo Franceschet"
output:
  ioslides_presentation:
    css: ../style.css
    incremental: yes
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE, message = FALSE, warning = FALSE)
```

## Overview

* the goal of a model is to provide a simple low-dimensional summary of a dataset
* ideally, the model will capture true **signals** (i.e. patterns generated by the phenomenon of interest), and ignore **noise** (i.e. random variation that youâ€™re not interested in)
* we are going to use models as a tool for exploration (**hypothesis generations**), and not for confirming that an hypothesis is true (**hypothesis confirmation**)

## Model = patterns + residuals

We're going to use models to partition data into **patterns** (signal) and **residuals** (noise). 

$$observed = pattern + residual$$

There are two parts to a model:

1.  First, you define a __family of models__ that express a precise, but 
    generic, pattern that you want to capture. For example, the pattern 
    might be a straight line, or a quadatric curve. You will express
    the model family as an equation like $$y = a_1 \cdot x + a_2$$ or 
    $$y = a_1 \cdot x^{a_2}$$ Here, $x$ and $y$ are known variables from your
    data, and $a_1$ and $a_2$ are parameters that can vary to capture 
    different patterns.

1.  Next, you generate a __fitted model__ by finding the model from the 
    family that is the closest to your data. This takes the generic model 
    family and makes it specific, like $$y = 3 \cdot x + 7$$ or $$y = 9 \cdot x ^ 2$$


## The map is not the territory

It's important to understand that a fitted model is just the closest model from a family of models. 

That implies that you have the *best* model (according to some criteria); it doesn't imply that you have a *good* model and it certainly doesn't imply that the model is *true*. 

> The map is not the territory

> All models are wrong, but some are useful

## Code

```{r}
library(dplyr)
library(ggplot2)
library(modelr)

# dataset
sim1

# scatter plot
ggplot(sim1, aes(x,y)) + geom_point()

# correlation coefficient
cor(sim1$x, sim1$y)

# linear model 
mod1 <- lm(y ~ x, data = sim1)

# model (all information)
summary(mod1)

# coefficients
mod1$coefficients

```

The model predics $y$ in terms of $x$ using the following linear relationship:

$$
y = 4.220822 + 2.051533 \cdot x
$$

```{r}
# visualizing the model
ggplot(sim1, aes(x,y)) + 
  geom_point() + 
  geom_abline(intercept = mod1$coefficients[1], 
              slope = mod1$coefficients[2], 
              color = "red")

```

## Response, prediction and residual

```{r, echo = FALSE}
dist1 <- sim1 %>% 
  mutate(
    dodge = rep(c(-1, 0, 1) / 20, 10),
    x1 = x + dodge,
    pred = 7 + x1 * 1.5
  )

ggplot(dist1, aes(x1, y)) + 
  geom_abline(intercept = 7, slope = 1.5, colour = "grey40") +
  geom_point(colour = "grey40") +
  geom_linerange(aes(ymin = y, ymax = pred), colour = "#3366FF") 
```

We have three interesting values in this plot for each value of variable $x$:

1. the value of variable $y$ observed in the dataset (the **response**);
2. the value of variable $y$ predicted by the model (the **prediction**)
3. the difference between observed and predicted values for variable $y$ (the **residual**)


* the **predictions** tells you the pattern that the model has captured
* the **residuals** tell you what the model has missed 
* residuals are powerful because they allow us to use models to remove striking patterns so we can study the subtler trends that remain

## A general method

```{r}
# To visualise a model, it is very useful to be able to generate 
# an evenly spaced grid of points from the data
(grid <- data_grid(sim1, x))

# add values predicted by the model over the grid
(grid <- add_predictions(grid, mod1))

# plot both observed and predicted values
ggplot(sim1, aes(x = x)) +
  geom_point(aes(y = y)) + # observed values
  geom_line(data = grid, aes(y = pred), colour = "red") # predicted values

# add predictions to the model
sim1 <- add_predictions(sim1, mod1)

# add residuals to the model
(sim1 <- add_residuals(sim1, mod1))

# histograph of residuals (mean is always 0)
ggplot(sim1, aes(resid)) + 
  geom_freqpoly(binwidth = 0.5)

# scatterplot of residuals (plot residuals as outcomes)
ggplot(sim1, aes(x, resid)) + 
  geom_ref_line(h = 0) +
  geom_point() 

```


